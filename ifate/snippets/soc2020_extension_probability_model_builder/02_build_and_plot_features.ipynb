{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Summary\n",
    "\n",
    "## Introduction\n",
    "\n",
    "- Process raw training data to have more features\n",
    "\n",
    "\n",
    "## What is in this notebook\n",
    "\n",
    "- Read in raw data from `01_create_training_data_and_apply_w2v_comparisons.ipynb`\n",
    "   - The first part of the version number referes to which output to read.\n",
    "- Process features\n",
    "   - Analyse level\n",
    "   - Delta features (score compared to best alternative)\n",
    "- Plot the features for common sense\n",
    "- Output to build models on    \n",
    "      \n",
    "## Output/Results\n",
    "\n",
    "- File in format `f'nsfg_data\\df_train_data_nlp__{run_version}.csv'`\n",
    " - This contains data for next stage\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version and Data Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_version = 'v4.2'\n",
    "version_in = run_version.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_train_data = f'df_train_data_nlp__{version_in}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports \n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ls_on_path(path):\n",
    "    \"\"\"\n",
    "    Run ls on a path in jupyter and display to notebook\n",
    "    Can't be imported as uses cell magic\n",
    "    Args: path (pathlib.WindowsPath): path created by pathlib\n",
    "    \"\"\"\n",
    "    userhome = os.path.expanduser(\"~\")\n",
    "    reformatted_path = ('\\\"' + str(path).replace('\\\\\\\\', '\\\"/\\\"') + '\\\"').replace('\\\"~\\\"','~').replace('~', userhome)\n",
    "    print(f'$ ls {path}')\n",
    "    !ls {reformatted_path}\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Colours\n",
    "blue =  '#79a5f7'\n",
    "red  =  '#ff9696'\n",
    "green=  '#9ebd9e'\n",
    "sns_colours = sns.color_palette()\n",
    "\n",
    "### Make the plots a nice size\n",
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': 'large',\n",
    "          'axes.labelsize': 'large',\n",
    "          'axes.titlesize':'large',\n",
    "          'xtick.labelsize':'large',\n",
    "          'ytick.labelsize':'large',\n",
    "          'figure.titlesize':'x-large'}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Path of where you have imported my functions\n",
    "current_path = os.getcwd()\n",
    "functions_path = Path('..', 'Functions')\n",
    "sys.path.append(str(functions_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pandas functions\n",
    "import laurie_pandas_functions as pd_funcs\n",
    "from laurie_pandas_functions import display_full\n",
    "\n",
    "## Matplotlib funcs\n",
    "import laurie_plotting_functions as plot_funcs\n",
    "from laurie_plotting_functions import get_ax, force_ax_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Useful when developing your functions\n",
    "from importlib import reload  \n",
    "reload(pd_funcs)\n",
    "reload(plot_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data\n",
    "Read the csvs from the paths and show the top two rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path('nsfg_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Path to sharepoint directory (created using Add shortcut to OneDrive button)\n",
    "path_hackathon_project = Path(\n",
    " '~', 'OneDrive - Department for Education', 'Documents - DSDST', 'General', 'Hackathon', '2022 Spring Hackathon', 'Project 1 SOC Assignment'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Features data Data\n",
    "df_train_raw = pd.read_csv(f'{path_data}/{filename_train_data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_raw['standard_code'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train_cols_processed = (\n",
    "    df_train_raw\n",
    "    .drop_duplicates()\n",
    "    .assign(ref_no=lambda df: df['standard_code'] + '_V' + df['version'].astype(str))\n",
    "    .assign(\n",
    "        score_rank_dense=lambda df: df.groupby('ref_no')['score'].rank('dense', ascending=False).astype(int),\n",
    "        score_rank=lambda df: df.groupby('ref_no')['score'].rank('first', ascending=False).astype(int),\n",
    "    )\n",
    "    .rename(columns={'soc2020_code': 'soc2020_code_assignment'})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out ones with multiple rank 1s\n",
    "- These typically have failed at the nlp stage for some reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n_rows_per_id = pd_funcs.count_n_rows_per_id(df_train_cols_processed.loc[lambda df: df['score_rank_dense']==1], 'ref_no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outliers = df_n_rows_per_id.loc[lambda df: df['n_rows_per_id'] > 300]\n",
    "outlier_std_refs = list(df_outliers['ref_no'].unique())\n",
    "df_train_filtered = df_train_cols_processed.loc[lambda df: ~df['ref_no'].isin(outlier_std_refs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Labels and Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_labelled = (\n",
    "    df_train_filtered\n",
    "    .assign(\n",
    "        autoassign_is_top=lambda df: df['match_rank'] == 1,\n",
    "        autoassign_in_top_2=lambda df: df['match_rank'].isin([1, 2]),\n",
    "        autoassign_in_top_3=lambda df: df['match_rank'].isin([1, 2, 3]),\n",
    "        autoassign_in_top_5=lambda df: df['match_rank'].isin([1, 2, 3, 4, 5]),\n",
    "        autoassign_is_ranked=lambda df: ~df['match_rank'].isna(),\n",
    "    )\n",
    ")\n",
    "\n",
    "label = 'autoassign_in_top_3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Param's from Jody's file\n",
    "df_level_params = pd.read_csv('data/soc_group_level_parameters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge it on\n",
    "df_train_w_features = (\n",
    "    df_train_labelled\n",
    "    .merge(df_level_params, on='level', how='left')\n",
    "    .assign(\n",
    "        soc_in_suggested_major_group = lambda df: ((df['soc_2020_major_group'] >= df['soc_major_group_lower']) & (df['soc_2020_major_group'] <= df['soc_major_group_upper'])).astype(int),\n",
    "        relative_distance_between_level_and_soc_major_group = lambda df:(df['soc_2020_major_group'] - df['soc_major_mean_train']) / df['soc_major_std_dev_train'],\n",
    "        absolute_relative_distance_between_level_and_soc_major_group = lambda df: np.abs(df['relative_distance_between_level_and_soc_major_group']),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is NEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_w_features['soc_2020_ext_is_nec'] = (\n",
    "    df_train_w_features['soc_2020_ext_title'].str.lower().str.contains('n.e.c.').fillna(0).astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delta Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_delta_feature(data, col, gb_key='ref_no', rank_col='score_rank'):\n",
    "    \"\"\"\n",
    "    For each column add two columns\n",
    "    - Add a column which is value of col - (value of col for next highest ranked row that is not the same row)\n",
    "    - Add a column which is value of col - (value of col for the next highest ranked row after that)\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Create table that has values for rank 1, 2 and 3 per gb_key.\n",
    "    df_alternatives = (\n",
    "        data\n",
    "        .loc[lambda df: df[rank_col] <= 3]\n",
    "        .pipe(pd.pivot_table, columns=rank_col, index=gb_key, values=col)\n",
    "        .reset_index()\n",
    "        .rename(columns={1: f'{col}_for_rank_1', 2: f'{col}_for_rank_2', 3: f'{col}_for_rank_3'}\n",
    "        \n",
    "        )\n",
    "    )\n",
    "\n",
    "    \n",
    "    df_out =  (\n",
    "        # Join alternatives on to main\n",
    "        data\n",
    "        .merge(df_alternatives, how='left', on=gb_key)\n",
    "        ## Calculate value - 1st and 2nd highest ranking alternatives\n",
    "        .assign(**{\n",
    "            f'{col}_minus_alt_1': lambda df: df[col] - np.where(df[rank_col] > 1, df[f'{col}_for_rank_1'], df[f'{col}_for_rank_2']),\n",
    "                                                                                               \n",
    "            f'{col}_minus_alt_2': lambda df: df[col] - np.where(df[rank_col] > 2, df[f'{col}_for_rank_2'], df[f'{col}_for_rank_3']),\n",
    "        }\n",
    "        )\n",
    "        # Drop alternative values\n",
    "        .drop([f'{col}_for_rank_1', f'{col}_for_rank_2', f'{col}_for_rank_3'], axis=1)\n",
    "    )\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas._testing import assert_frame_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_input = pd.DataFrame({\n",
    "    'ref_no': ['ST0001_V1.0', 'ST0001_V1.0', 'ST0001_V1.0', 'ST0002_V1.0', 'ST0002_V1.0', 'ST0002_V1.0'],\n",
    "    'score_soc_job_match_standard_title': [\n",
    "        0.5, \n",
    "        0.2, \n",
    "        0.1,\n",
    "        0.4, \n",
    "        0.6, \n",
    "        0.5,\n",
    "    ],\n",
    "}).assign(\n",
    "    score_rank=lambda df: df.groupby('ref_no')['score_soc_job_match_standard_title'].rank('first', ascending=False).astype(int),\n",
    ")\n",
    "\n",
    "\n",
    "df_expected = df_input.copy()\n",
    "\n",
    "df_expected['score_soc_job_match_standard_title_minus_alt_1'] = [\n",
    "            0.5 - 0.2,\n",
    "            0.2 - 0.5,\n",
    "            0.1 - 0.5,\n",
    "            0.4 - 0.6,\n",
    "            0.6 - 0.5,\n",
    "            0.5 - 0.6,\n",
    "]\n",
    "\n",
    "df_expected['score_soc_job_match_standard_title_minus_alt_2'] = [\n",
    "            0.5 - 0.1,\n",
    "            0.2 - 0.1,\n",
    "            0.1 - 0.2,\n",
    "            0.4 - 0.5,\n",
    "            0.6 - 0.4,\n",
    "            0.5 - 0.4,\n",
    "]\n",
    "\n",
    "\n",
    "df_result = add_delta_feature(df_input, 'score_soc_job_match_standard_title')\n",
    "\n",
    "assert_frame_equal(df_result, df_expected, check_like=True)\n",
    "\n",
    "display(df_result.style.set_table_styles(pd_funcs.get_lauries_table_styles()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train_w_delta_features = df_train_w_features.copy()\n",
    "\n",
    "for col in [ 'score_soc_job_match_standard_title', 'score_soc_job_match_typical_job', 'score_overview', 'soc_2020_matches_previous_assignment', 'soc_in_suggested_major_group', 'absolute_relative_distance_between_level_and_soc_major_group']:\n",
    "    df_train_w_delta_features = add_delta_feature(df_train_w_delta_features, col=col, gb_key='ref_no', rank_col = 'score_rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_w_delta_features.head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Final Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_w_delta_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Top Choice\n",
    "df_train_original_best = (\n",
    "    df_train\n",
    "    .loc[lambda df: df['score_rank']==1]\n",
    ")\n",
    "\n",
    "pd_funcs.agg_df_by_cols(df_train_original_best, 'autoassign_in_top_3', display_df=True, do_total=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which Rank Do We Need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Check Truth\n",
    "df_train_score_rank = pd_funcs.agg_df_by_cols(\n",
    "    df_train\n",
    "    .loc[lambda df: df[label]==True],\n",
    "    'score_rank',\n",
    "    return_df=True,\n",
    "    do_total=False,\n",
    "    sort_by_cols=True\n",
    ")\n",
    "\n",
    "df_train_score_rank['cumu_pct_rows'] = df_train_score_rank['pct_rows'].cumsum()\n",
    "\n",
    "(\n",
    "    df_train_score_rank\n",
    "    .set_index('score_rank')\n",
    "    .style\n",
    "    .set_table_styles(pd_funcs.get_lauries_table_styles())\n",
    "    .format({\n",
    "        'pct_rows': '{:,.1f}%',\n",
    "        'cumu_pct_rows': '{:,.1f}%',\n",
    "    }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    'score_soc_job_match_standard_title',\n",
    "    'score_soc_job_match_standard_title_minus_alt_1',\n",
    "    'score_soc_job_match_standard_title_minus_alt_2',\n",
    "    'score_soc_job_match_typical_job',\n",
    "    'score_soc_job_match_typical_job_minus_alt_1',\n",
    "    'score_soc_job_match_typical_job_minus_alt_2',\n",
    "    'score_overview',\n",
    "    'score_overview_minus_alt_1',\n",
    "    'score_overview_minus_alt_2',\n",
    "    'soc_2020_matches_previous_assignment',\n",
    "    'soc_2020_matches_previous_assignment_minus_alt_1',\n",
    "    'soc_2020_matches_previous_assignment_minus_alt_2',\n",
    "    'soc_in_suggested_major_group',\n",
    "    'soc_in_suggested_major_group_minus_alt_1',\n",
    "    'soc_in_suggested_major_group_minus_alt_2',\n",
    "    'soc_2020_ext_is_nec',\n",
    "    'is_core_and_options',\n",
    "]\n",
    "\n",
    "\n",
    "data = df_train\n",
    "\n",
    "for col in features:\n",
    "    \n",
    "    ax_hist, ax_bar = get_ax(ncols=2, width=15)\n",
    "    \n",
    "    sns.histplot(\n",
    "        data = data,\n",
    "        x = col, hue = label,\n",
    "        ax = ax_hist, stat = 'probability', common_norm = False, bins=101\n",
    "    )\n",
    "    \n",
    "    sns.barplot(\n",
    "        data = data,\n",
    "        x = col, \n",
    "        y = label,\n",
    "        ax = ax_bar,\n",
    "        orient = 'h'\n",
    "    )\n",
    "\n",
    "    plot_funcs.annotate_hbar_ax(ax_bar, annotate_format='{:,.2f}')\n",
    "        \n",
    "    force_ax_grid([ax_hist, ax_bar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = (\n",
    "    df_train\n",
    "    .loc[lambda df: df['score_rank'] <= 50]\n",
    ")\n",
    "\n",
    "for col in features:\n",
    "    \n",
    "    ax_hist, ax_bar = get_ax(ncols=2, width=15)\n",
    "    \n",
    "    sns.histplot(\n",
    "        data = data,\n",
    "        x = col, hue = label,\n",
    "        ax = ax_hist, stat = 'probability', common_norm = False, bins=101\n",
    "    )\n",
    "    \n",
    "    sns.barplot(\n",
    "        data = data,\n",
    "        x = col, \n",
    "        y = label,\n",
    "        ax = ax_bar,\n",
    "        orient = 'h'\n",
    "    )\n",
    "\n",
    "    plot_funcs.annotate_hbar_ax(ax_bar, annotate_format='{:,.2f}')\n",
    "\n",
    "    \n",
    "    \n",
    "    force_ax_grid([ax_hist, ax_bar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    df_train\n",
    "    .loc[lambda df: df['score_rank'] <= 10]\n",
    ")\n",
    "\n",
    "for col in [\n",
    "    'absolute_relative_distance_between_level_and_soc_major_group',\n",
    "    'absolute_relative_distance_between_level_and_soc_major_group_minus_alt_1',\n",
    "    'absolute_relative_distance_between_level_and_soc_major_group_minus_alt_2',        \n",
    "]:\n",
    "    \n",
    "    ax_hist, ax_bar = get_ax(ncols=2, width=15)\n",
    "    \n",
    "    end = 5\n",
    "    start = 0\n",
    "    if '_alt_' in col: start = -end\n",
    "    bins = np.linspace(start, end, 51)\n",
    "    \n",
    "    sns.histplot(\n",
    "        data = data,\n",
    "        x = col, hue = label,\n",
    "        ax = ax_hist, stat = 'percent', common_norm = False,\n",
    "        bins=bins,\n",
    "    )\n",
    "    \n",
    "    sns.barplot(\n",
    "        data = data,\n",
    "        x = col, \n",
    "        y = label,\n",
    "        ax = ax_bar,\n",
    "        orient = 'h'\n",
    "    )\n",
    "\n",
    "    plot_funcs.annotate_hbar_ax(ax_bar, annotate_format='{:,.2f}')\n",
    "\n",
    "        \n",
    "    force_ax_grid([ax_hist, ax_bar])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Features with Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train.head(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(f'{path_data}/df_train_w_features__{run_version}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Laurie's Analytical Kernel",
   "language": "python",
   "name": "venv_ana"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
