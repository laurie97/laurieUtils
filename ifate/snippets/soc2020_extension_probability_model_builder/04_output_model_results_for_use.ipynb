{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Summary\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Use probabilites produced in notebook 03 to create useful data products for SOC assignement.\n",
    "\n",
    "         \n",
    "## Output/Results\n",
    "\n",
    "1. List of prioritised standards\n",
    "   - `f'nsfg_data/soc_assignment_prioritisation_20230222.xlsx'`\n",
    "\n",
    "\n",
    "2. Information for RMs to determine best match for top prioritised standards\n",
    "   - `nsfg_data\\export_results_prio_Construction and the built environment_v3.2.1__20230222_1019.xlsx`\n",
    "\n",
    "## Recommendation for Viewing Code\n",
    "\n",
    "- The headings in this notebook follow Markdown convention i.e # means H1 and ## is H2\n",
    "- I recommend adding a Table of Contents add on to see the structure of this notebook in the best way\n",
    "- Here is a great package that can add a ToC to jupyter notebooks: https://github.com/minrk/ipython_extensions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_version = 'v4.2.2' \n",
    "training_data_version = run_version.split('.')[0]\n",
    "label = 'autoassign_in_top_3'\n",
    "best_model = 'model_b'\n",
    "prob_col = f'{best_model}_output_prob'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports \n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Path of where you have imported my functions\n",
    "current_path = os.getcwd()\n",
    "functions_path = Path(current_path, '..', 'functions')\n",
    "sys.path.append(str(functions_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pandas functions\n",
    "import laurie_pandas_functions as pd_funcs\n",
    "from laurie_pandas_functions import display_full\n",
    "\n",
    "## Matplotlib funcs\n",
    "import laurie_plotting_functions as plot_funcs\n",
    "from laurie_plotting_functions import get_ax, force_ax_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Useful when developing your functions\n",
    "from importlib import reload  \n",
    "reload(pd_funcs)\n",
    "reload(plot_funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ls_on_path(path):\n",
    "    \"\"\"\n",
    "    Run ls on a path in jupyter and display to notebook\n",
    "    Can't be imported as uses cell magic\n",
    "    Args: path (pathlib.WindowsPath): path created by pathlib\n",
    "    \"\"\"\n",
    "    userhome = os.path.expanduser(\"~\")\n",
    "    reformatted_path = ('\\\"' + str(path).replace('\\\\\\\\', '\\\"/\\\"') + '\\\"').replace('\\\"~\\\"','~').replace('~', userhome)\n",
    "    print(f'$ ls {path}')\n",
    "    !ls {reformatted_path}\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Colours\n",
    "blue =  '#79a5f7'\n",
    "red  =  '#ff9696'\n",
    "green=  '#9ebd9e'\n",
    "sns_colours = sns.color_palette()\n",
    "\n",
    "### Make the plots a nice size\n",
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': 'large',\n",
    "          'axes.labelsize': 'large',\n",
    "          'axes.titlesize':'large',\n",
    "          'xtick.labelsize':'large',\n",
    "          'ytick.labelsize':'large',\n",
    "          'figure.titlesize':'x-large'}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data\n",
    "Read the csvs from the paths and show the top two rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prediction_export = Path('nsfg_data', f'df_output_modelling_{run_version}.csv')\n",
    "df_predictions = pd.read_csv(path_prediction_export)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_features_import = Path('nsfg_data', f'df_train_data_nlp__{training_data_version}.csv')\n",
    "df_features = pd.read_csv(path_features_import)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = 'https://www.instituteforapprenticeships.org/api/apprenticeshipstandards'\n",
    "\n",
    "import requests\n",
    "\n",
    "def query_url_to_df(url):\n",
    "    response = requests.get(url)\n",
    "    result = response.json()\n",
    "    data = pd.DataFrame.from_records(result)\n",
    "    return data\n",
    "\n",
    "df_api_raw = query_url_to_df(api_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api_snaked = pd_funcs.apply_snake_case_to_df(df_api_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_to_standard_renamer = {\n",
    "    'reference_number': 'standard_code',\n",
    "    'versionNumber': 'version',\n",
    "    'standard_page_url': 'standard_page_url',\n",
    "}\n",
    "\n",
    "df_api_renamed = (\n",
    "    df_api_snaked\n",
    "    .rename(columns=api_to_standard_renamer)\n",
    "    [api_to_standard_renamer.values()]\n",
    "    .assign(version=lambda df: df['version'].astype(float))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_cols = list(set(df_predictions.columns) - set(df_features.columns))\n",
    "merge_cols = ['standard_code', 'version', 'soc_2020_ext_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_display = (\n",
    "    df_features\n",
    "    .merge(\n",
    "        df_predictions[merge_cols+prediction_cols],\n",
    "        how='left',\n",
    "        on=merge_cols,\n",
    "        indicator='_merge_with_prediction',\n",
    "    )\n",
    "    .merge(\n",
    "        df_api_renamed,\n",
    "        how='left',\n",
    "        on=['standard_code', 'version'],\n",
    "        indicator='_merge_with_api',\n",
    "    )\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_funcs.agg_df_by_cols(df_display, '_merge_with_prediction', display_df=True)\n",
    "pd_funcs.agg_df_by_cols(df_display.drop_duplicates('standard_code'), '_merge_with_api', display_df=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_display = df_display.drop(['_merge_with_prediction', '_merge_with_api'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add some new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_display['soc_major_group_expected_range'] =  (df_display['soc_major_group_lower'].astype(str) + ' - ' + df_display['soc_major_group_upper'].astype(str)).str.replace('.0', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_display['ids_soc_2020_code'] = np.where(\n",
    "    df_display['ids_soc_2020_code'].isna(),\n",
    "    'N/A',\n",
    "    df_display['ids_soc_2020_code'].astype(str).str[:4],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_no_cols = [\n",
    "    'soc_2020_matches_previous_assignment',\n",
    "    'soc_in_suggested_major_group',\n",
    "]\n",
    "\n",
    "for c in yes_no_cols:\n",
    "    df_display[c] = np.where(\n",
    "        df_display[c] > 0,\n",
    "        'Yes',\n",
    "        np.where(\n",
    "            df_display[c] == 0,\n",
    "            'No',\n",
    "            'N/A'\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_display['match_rank_label'] = np.where(\n",
    "    df_display['match_rank'].isna(),\n",
    "    '',\n",
    "    np.where(\n",
    "        df_display['match_rank'] == 1,\n",
    "        'Primary',\n",
    "        'Alternative #' + (df_display['match_rank'].fillna(0) - 1).astype(int).astype(str),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rayg_label = {\n",
    "    'g': 'Strong Match',\n",
    "    'y': 'Medium Match',\n",
    "    'a': 'Weak Match',\n",
    "    'r': 'Unlikely to be a match',\n",
    "}\n",
    "\n",
    "dict_rayg_colours = {\n",
    "    'g': '#9ebd9e',\n",
    "    'y': '#ffff96',\n",
    "    'a': '#ffcb96',\n",
    "    'r': '#ff9696',\n",
    "}\n",
    "\n",
    "case_when_prob_col_label = {\n",
    "    dict_rayg_label['g']: df_display[prob_col] > 0.5,\n",
    "    dict_rayg_label['y']: df_display[prob_col] > 0.25,\n",
    "    dict_rayg_label['a']: df_display[prob_col] > 0.02,\n",
    "    dict_rayg_label['r']: df_display[prob_col] >= -0.01,\n",
    "}\n",
    "\n",
    "df_display['prob_col_label'] = np.select(condlist=case_when_prob_col_label.values(), choicelist=case_when_prob_col_label.keys(), default='N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_funcs.agg_df_by_cols(df_display.loc[lambda df: df['rank_model_b'] <= 10], label, set_cols='prob_col_label', display_df=True, do_total=False, sort_by_cols=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Range by SOC Major Group\n",
    "- No-one will know what SOC major group is\n",
    "- But everyone will know what Level is\n",
    "- So easy to say is standard within expected levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Param's from Jody's file\n",
    "df_level_params = pd.read_csv('data/soc_group_level_parameters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adjust from level to soc mg range to soc mg to level range\n",
    "min_soc_mg = df_level_params['soc_major_group_lower'].min()\n",
    "max_soc_mg = df_level_params['soc_major_group_upper'].max()\n",
    "\n",
    "soc_major_groups = []\n",
    "min_levels = []\n",
    "max_levels = []\n",
    "\n",
    "for s in range(min_soc_mg, max_soc_mg+1):\n",
    "    \n",
    "    df_range = (\n",
    "        df_level_params\n",
    "        .loc[lambda df: df['soc_major_group_lower'] <= s]\n",
    "        .loc[lambda df: df['soc_major_group_upper'] >= s]\n",
    "    )\n",
    "    \n",
    "    soc_major_groups.append(s)\n",
    "    min_levels.append(df_range['level'].min())\n",
    "    max_levels.append(df_range['level'].max())\n",
    "\n",
    "df_soc_major_group_params = pd.DataFrame(\n",
    "    {\n",
    "        'soc_2020_major_group': soc_major_groups,\n",
    "        'level_lower': min_levels,\n",
    "        'level_upper': max_levels,\n",
    "    }\n",
    "\n",
    ")\n",
    "\n",
    "df_soc_major_group_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge to display\n",
    "df_display = (\n",
    "    df_display\n",
    "    .merge(df_soc_major_group_params, on='soc_2020_major_group', suffixes=('_', ''))\n",
    ")\n",
    "\n",
    "\n",
    "df_display['within_level_expected_range'] = np.where(\n",
    "    (df_display['level'] >= df_display['level_lower']) & (df_display['level'] <= df_display['level_upper']),\n",
    "    'Yes',\n",
    "    'No',\n",
    ")\n",
    "\n",
    "df_display['within_level_expected_range_display'] =  df_display['within_level_expected_range'] + (' (L' + df_display['level_lower'].astype(str) + ' - ' + df_display['level_upper'].astype(str)+')').str.replace('.0', '')\n",
    "\n",
    "\n",
    "level_range_cols = ['level_lower', 'level_upper']\n",
    "for c in level_range_cols:\n",
    "    old_col = f'{c}_'\n",
    "    if old_col in df_display:\n",
    "        df_display = df_display.drop(old_col, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prioritasation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prioritasation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_display['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_prio = (\n",
    "    df_display\n",
    "    .assign(\n",
    "        prob_of_top_gatsby_match=lambda df: np.where(\n",
    "            df['autoassign_is_top'],\n",
    "            df[prob_col],\n",
    "            None,\n",
    "        ),\n",
    "        prob_of_gatsby_match=lambda df: np.where(\n",
    "            df['autoassign_is_ranked'],\n",
    "            df[prob_col],\n",
    "            None,\n",
    "        ),\n",
    "        prob_of_gatsby_match_low_pct=lambda df: np.where(\n",
    "            df['autoassign_is_ranked'],\n",
    "            (df[prob_col] < 0.02).astype(int),\n",
    "            None,\n",
    "        ),\n",
    "        top_gatsby_match_soc_2020_ext_code=lambda df: np.where(\n",
    "            df['autoassign_is_top'],\n",
    "            df['soc_2020_ext_code'],\n",
    "            None,\n",
    "        ),\n",
    "        top_gatsby_match_soc_2020_ext_title=lambda df: np.where(\n",
    "            df['autoassign_is_top'],\n",
    "            df['soc_2020_ext_title'].astype(str),\n",
    "            '',\n",
    "        ),\n",
    "    )\n",
    "    .groupby(['route', 'standard_code', 'standard_title'])\n",
    "    .agg(**{\n",
    "            'max_prob': (prob_col, max),\n",
    "            'min_prob_of_gatsby_match': ('prob_of_gatsby_match', min),\n",
    "            'prob_of_top_gatsby_match': ('prob_of_top_gatsby_match', max),\n",
    "            'mean_prob_of_gatsby_match': ('prob_of_gatsby_match', 'mean'),\n",
    "            'n_low_prob_gatsby_matches': ('prob_of_gatsby_match_low_pct', sum),\n",
    "            'top_gatsby_match_soc_2020_ext_title': ('top_gatsby_match_soc_2020_ext_title', max),\n",
    "            'n_matches': ('autoassign_is_ranked', 'sum'),\n",
    "            'status': ('status', 'max'),\n",
    "        }\n",
    "    )  \n",
    "    .assign(\n",
    "        delta_in_max_prob=lambda df: df['max_prob'] - df['prob_of_top_gatsby_match'],\n",
    "        delta_mean_prob_of_gatsby_match=lambda df: df['max_prob'] - df['mean_prob_of_gatsby_match'],\n",
    "    )\n",
    "    .assign(\n",
    "        prio_low = lambda df: df['n_low_prob_gatsby_matches']\n",
    "    )\n",
    "    .assign(\n",
    "        prio_low_norm = lambda df: df['prio_low'] / df['prio_low'].max()\n",
    "    )\n",
    "    .assign(\n",
    "        prio_reweighted = lambda df: (df['delta_in_max_prob'] + df['prio_low_norm']) / 2 + (1 - df['mean_prob_of_gatsby_match']) * 0.001\n",
    "    )\n",
    "    .assign(\n",
    "        prio_ranked = lambda df: df['prio_reweighted'].rank(method='first', ascending=False)\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prio['prio_rank_display'] = np.where(\n",
    "    df_prio['prio_ranked'].isna(),\n",
    "    'Un-ranked',\n",
    "    (df_prio['prio_ranked'].astype(str) + ' (of ' + str(df_prio.shape[0]) + ')').str.replace(r'\\.0', ''),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Prio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_full(\n",
    "    df_prio\n",
    "    .sort_values(['prio_ranked'])\n",
    "    .head(5000)\n",
    "    .set_index(['prio_ranked', 'standard_code'])\n",
    "    [['prio_rank_display', 'route', 'standard_title', 'prio_reweighted', 'delta_in_max_prob', 'prio_low_norm', 'n_low_prob_gatsby_matches', 'prob_of_top_gatsby_match', 'mean_prob_of_gatsby_match']]\n",
    "    , force=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate Prioritisation By Route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prio = (\n",
    "    df_prio\n",
    "    .assign(\n",
    "        standards_in_top_100 = lambda df: df['prio_ranked'] <= 100,\n",
    "        standards_in_top_250 = lambda df: df['prio_ranked'] <= 250,\n",
    "    )\n",
    ")\n",
    "\n",
    "df_prio_by_route = (\n",
    "    df_prio\n",
    "    .groupby('route')\n",
    "    .agg(**{\n",
    "        'standards': ('standard_code', 'count'),\n",
    "        'standards_in_top_100': ('standards_in_top_100', sum),\n",
    "        'standards_in_top_250': ('standards_in_top_250', sum),\n",
    "    }\n",
    "    )\n",
    "    .assign(\n",
    "        pct_standards_in_top_100 = lambda df: df['standards_in_top_100'] * 100 / df['standards'],\n",
    "        pct_standards_in_top_250 = lambda df: df['standards_in_top_250'] * 100 / df['standards'],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['standards', 'standards_in_top_100', 'pct_standards_in_top_100']\n",
    "\n",
    "st_cols = ['standards']\n",
    "top_cols = [c for c in cols if c.startswith('standards')]\n",
    "rel_cols = [c for c in cols if c.startswith('pct_standards_in')]\n",
    "\n",
    "(\n",
    "    df_prio_by_route\n",
    "    [cols]\n",
    "    .style\n",
    "    .format('{:,.1f}%', subset=rel_cols)\n",
    "    .bar(width=70, align='mid', subset=st_cols, color=blue)\n",
    "    .bar(width=70, align='mid', subset=top_cols, color=green)\n",
    "    .bar(width=70, align='mid', subset=rel_cols, color=red)\n",
    "    .set_table_styles(pd_funcs.get_lauries_table_styles())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols = ['standards', 'standards_in_top_250', 'pct_standards_in_top_250']\n",
    "\n",
    "st_cols = ['standards']\n",
    "standards_in_top_cols = [c for c in cols if c.startswith('standards_in')]\n",
    "rel_cols = [c for c in cols if c.startswith('pct_standards_in')]\n",
    "\n",
    "(\n",
    "    df_prio_by_route\n",
    "    [cols]\n",
    "    .style\n",
    "    .format('{:,.1f}%', subset=rel_cols)\n",
    "    .bar(width=70, align='mid', subset=st_cols, color=blue)\n",
    "    .bar(width=70, align='mid', subset=standards_in_top_cols, color=green)\n",
    "    .bar(width=70, align='mid', subset=rel_cols, color=red)\n",
    "    .set_table_styles(pd_funcs.get_lauries_table_styles())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add to df_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_display = (\n",
    "    df_display\n",
    "    .merge(\n",
    "        df_prio[['standard_code', 'prio_rank_display']],\n",
    "        on='standard_code',\n",
    "        how='left',\n",
    "        suffixes=('__', '')\n",
    "    )\n",
    ")\n",
    "\n",
    "if 'prio_rank_display__' in df_display.columns:\n",
    "    df_display = df_display.drop('prio_rank_display__', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_prio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Prio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_prio_display_rename = {\n",
    "    'route': 'Route', \n",
    "    'standard_code': 'ST Code', \n",
    "    'standard_title': 'Standard Title', \n",
    "    'prio_ranked': 'Priority Rank',\n",
    "    'delta_in_max_prob': 'Difference in probability between Gatsby and AI\\'s Top Match',\n",
    "    'n_low_prob_gatsby_matches': 'Number of Unlikely Gatsby Matches',\n",
    "    'status': 'Standard Status',\n",
    "}\n",
    "\n",
    "df_prio_displayed = (\n",
    "    df_prio\n",
    "    .loc[lambda df: df['prio_ranked'] <= 250]\n",
    "    .sort_values('prio_ranked')\n",
    "    .assign(prio_ranked = lambda df: df['prio_ranked'].astype(int))\n",
    "    .assign(delta_in_max_prob = lambda df: (df['delta_in_max_prob']*100.0).round(1).astype(str)+'%')\n",
    "    [dict_prio_display_rename.keys()]\n",
    "    .rename(columns=dict_prio_display_rename)\n",
    "    .set_index(dict_prio_display_rename['prio_ranked'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime.today().strftime('%Y%m%d')\n",
    "df_prio_displayed.to_excel(f'nsfg_data/soc_assignment_prioritisation_{today}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_full(df_display.head(3).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_cols = [\n",
    "    'standard_code',\n",
    "    'standard_title',\n",
    "    'route',\n",
    "    'prio_rank_display',\n",
    "    'level',\n",
    "    'standard_overview',\n",
    "    'option_titles'    \n",
    "]\n",
    "\n",
    "soc_cols = [\n",
    "    'soc_2020_ext_code',\n",
    "    'soc_2020_ext_title',\n",
    "    'match_rank_label',\n",
    "    'prob_col_label',\n",
    "    'soc_job_matches_standard_title',\n",
    "    'soc_2020_ext_description',\n",
    "    'standard_typical_job_title',\n",
    "    'soc_job_matches_typical_job',\n",
    "    'within_level_expected_range_display',    \n",
    "]\n",
    "\n",
    "cols_dictionary = {\n",
    "    'standard_code': 'Standard Code',\n",
    "    'standard_title': 'Standard Title',\n",
    "    'soc_2020_ext_code': 'SOC2020 Ext Code',\n",
    "    'soc_2020_ext_title': 'SOC2020 Ext Title',\n",
    "    'match_rank_label': 'Current Assignment',\n",
    "    'prio_rank_display': 'QA Priority Rank',\n",
    "    prob_col: 'IfATE Model Probability',\n",
    "    'prob_col_label': 'IfATE Model Assessment',\n",
    "    'soc_2020_matches_previous_assignment': 'SOC2020 consistent with previous assignment',\n",
    "    'ids_soc_2020_code': 'SOC 2020 Assigned on IDS',\n",
    "    'ids_soc_2020_rationale': 'IDS SOC 2020 Rationale',\n",
    "    'score_soc_job_match_standard_title': 'Similarity - SOC Job & Standard Title',\n",
    "    'soc_job_matches_standard_title': 'Soc Job Role Matched to Standard Title',\n",
    "    'score_soc_job_match_typical_job': 'Similarity - Standard Typical Job Role & SOC Job',\n",
    "    'standard_typical_job_title': 'Best match between Standard Typical Job Titles and SOC Job Roles',\n",
    "    'soc_job_matches_typical_job': '',\n",
    "    'score_overview': 'Similarity Description',\n",
    "    'standard_overview': 'Standard Overview',\n",
    "    'soc_2020_ext_description': 'SOC2020 Ext Description',\n",
    "    'soc_in_suggested_major_group': 'SOC in suggested major group',\n",
    "    'level': 'Level',\n",
    "    'soc_major_group_expected_range': 'Expected SOC Major Group Range',\n",
    "    'soc_2020_major_group': 'SOC 2020 Major Group',\n",
    "    'route': 'Route',\n",
    "    'standard_page_url': 'IfATE Webpage',\n",
    "    'within_level_expected_range_display': 'Standard meets Expected Level Range for this SOC Code',\n",
    "    'option_titles': 'Option Titles',\n",
    "}\n",
    "\n",
    "cols_meaning_dictionary = {\n",
    "    'standard_code': 'The ST code of the Apprenticeship Standard',\n",
    "    'standard_title': 'The Apprenticeship Standard Title',\n",
    "    'soc_2020_ext_code': 'The 6 Digit SOC2020 Sub-unit Group Code',\n",
    "    'soc_2020_ext_title': 'SOC2020 Sub-unit Group Name',\n",
    "    'match_rank_label': 'The Current Assignment in IDS, which is initially taken from a data-set provided by Gatsby, a independant body.',\n",
    "    'prio_rank_display': 'What priority for QA has been assigned to this Standard',\n",
    "    'prob_col_label': (\n",
    "        'For every standard IfATE runs an AI model that independently assesses how strong the match between the SOC 2020 SUG code and Apprenticeship Standard. '\n",
    "        'This is then transformed to a RAYG assessment of the strength of the match, where Green means likely to be a match, and Red means unlikely to be a match. '\n",
    "        'This model can accelerate the mapping process, but bare in mind that this model is sometimes wrong, so use good judgement.'   \n",
    "    ),\n",
    "    'soc_job_matches_standard_title': 'Soc Job Role Matched to Standard Title',\n",
    "    'standard_typical_job_title': 'Best match between Standard Typical Job Titles and SOC Job Roles',\n",
    "    'soc_job_matches_typical_job': '',\n",
    "    'standard_overview': 'Standard Overview',\n",
    "    'soc_2020_ext_description': 'SOC2020 Ext Description',\n",
    "    'level': 'Level',\n",
    "    'route': 'Route',\n",
    "    'standard_page_url': 'IfATE Webpage',\n",
    "    'within_level_expected_range_display': (\n",
    "        'The SOC 2020 Major Group (1st digit of the code) indicates how senior this role is, '\n",
    "        'and we can infer the range of Standard levels that are usually related to this level of seniority. '\n",
    "        'This column shows if the standard meets the expected level range, '\n",
    "        'and the full expected level range is shown in brackets.'\n",
    "    ),\n",
    "    'option_titles': 'Titles of Options (if Standard is Core and Options)',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Intro text above column description on explanation text\n",
    "creation_time = str(datetime.datetime.today())[:16]\n",
    "\n",
    "intro_text = [\n",
    "    ['This dataset provides the information to accelerate the process of identifying the 6-digit SOC 2020 Sub-Unit Group (SUG) Codes from ONS that best represent our Occupational Standards.'],\n",
    "    [f'Creation Date:  {creation_time}'],\n",
    "    [''],\n",
    "    ['Context:'],\n",
    "    ['-> IfATE has commited to keeping an up-to-date registry of which SOC 2020 SUG codes best represent the Occupational Standards, and this will be published via the Occupational Maps'],\n",
    "    ['-> This will enable the whole education data ecosystem to link to our products and vice-versa'],\n",
    "    ['-> Find more about SOC 2020 Extension Codes at', 'https://www.ons.gov.uk/methodology/classificationsandstandards/standardoccupationalclassificationsoc/standardoccupationalclassificationsocextensionproject'],\n",
    "    ['-> Find more about Occupational Standards at', 'https://www.instituteforapprenticeships.org/occupational-standards/'],\n",
    "    [''],\n",
    "    ['Data Explanation:'],\n",
    "    ['-> At the top we show information about the standard and a link to the Standard page, which contains more information about the Standard.'],\n",
    "    ['-> Then, we show useful links for information that help the process'],\n",
    "    ['-> Below, we show SOC SUG codes that are current stored in IDS as matches to the Standard. AI model assesses the strength of each map in the form of a RAYG rating is shown. Then there is other information that relates to the quality of match.'],\n",
    "    ['-> Finally, we show the 20 SOC SUG codes that are most likely to match to the Standard according to the AI. This is to enable us to quickly check that there are no better matches.'],\n",
    "    ['-> Most of the time 1-3 SOC 2020 SUG Codes should be sufficient to cover the Occupation, although occasionaly more is required, especially for core and options standards.'],\n",
    "    [''],\n",
    "    ['Column descriptions:'],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_cols = ['standard_title', 'soc_2020_ext_title', 'soc_job_matches_standard_title', 'standard_typical_job_title', 'soc_job_matches_typical_job', 'route', 'prob_col_label', 'within_level_expected_range_display']\n",
    "title_cols = [cols_dictionary[c] for c in title_cols]\n",
    "        \n",
    "medium_text_cols = ['standard_overview', 'ids_soc_2020_rationale']\n",
    "medium_text_cols = [cols_dictionary[c] for c in medium_text_cols]\n",
    "\n",
    "long_text_cols = ['soc_2020_ext_description']\n",
    "long_text_cols = [cols_dictionary[c] for c in long_text_cols]\n",
    "long_text_cols.append('Delivery Comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_df_to_excel(data, writer, sheet_name, startrow, index=True):\n",
    "    \n",
    "    header_format = writer.book.add_format({\n",
    "        'bold': True,\n",
    "        'text_wrap': True,\n",
    "        'valign': 'top',\n",
    "        'border': 1}\n",
    "    )\n",
    "    \n",
    "    if data.shape[0] == 0:\n",
    "        print('No Data Available')\n",
    "        worksheet = writer.sheets[sheet_name]\n",
    "        worksheet.write(startrow , 0, 'No Data Available')\n",
    "\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        data_styled = data.style\n",
    "        \n",
    "        data.to_excel(writer, encoding='utf-8', sheet_name=sheet_name, startrow=startrow+1, header=False, index=index)\n",
    "\n",
    "        worksheet = writer.sheets[sheet_name]\n",
    "        if index:\n",
    "            header_names = list(data.index.names) + list(data.columns.values)\n",
    "        else:\n",
    "            header_names = list(data.columns.values)\n",
    "            \n",
    "        for col_num, value in enumerate(header_names):\n",
    "            worksheet.write(startrow, col_num, value, header_format) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_intro(writer, list_text, dict_col_descriptions, sheet_name_intro):\n",
    "    \"\"\"\n",
    "    Function to write an intro/explanation page\n",
    "    \n",
    "    Args:\n",
    "    - writer (pd.ExcelWriter): The excel writer object\n",
    "    - list_text (list of list of strings): List of of list of text to put in cells. Outer list represents rows, inner list represents columns in that row.\n",
    "    - dict_explanations (dict): Dict representating col variable name and explanation.\n",
    "    - sheet_name_intro (str): Name of sheet to put explanation in.\n",
    "    \"\"\"\n",
    "    \n",
    "    cols_used = standard_cols + soc_cols\n",
    "    col_names = []\n",
    "    col_descriptions = []\n",
    "    for c in cols_used:\n",
    "        if c != '':\n",
    "            col_names.append(cols_dictionary[c])\n",
    "            col_descriptions.append(dict_col_descriptions[c])\n",
    "        \n",
    "    df_descriptions = pd.DataFrame({'Column Name': col_names, 'Explanation': col_descriptions})\n",
    "    \n",
    "    start_row_descriptions = len(list_text)\n",
    "    end_row_descriptions = len(list_text) + len(df_descriptions) + 1\n",
    "    write_df_to_excel(df_descriptions, writer, sheet_name=sheet_name_intro, startrow=start_row_descriptions, index=False)\n",
    "\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets[sheet_name_intro]    \n",
    "    \n",
    "    for y, line in enumerate(list_text):\n",
    "        for x, cell in enumerate(line):\n",
    "            worksheet.write(y, x, cell)\n",
    "\n",
    "    ## Set up format\n",
    "    wrap_format = workbook.add_format({'text_wrap': True, 'align': 'left'})\n",
    "    worksheet.set_column(0, 0, width=60)\n",
    "    worksheet.set_column(1, 1, width=100, cell_format=wrap_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contents(writer, st_codes, df_display, sheet_name_contents='Contents'):\n",
    "    \"\"\"\n",
    "    Function to write an contents page\n",
    "    \n",
    "    Args:\n",
    "    - writer (pd.ExcelWriter): The excel writer object\n",
    "    - st_codes (list of  strings): List of ST codes of form 'ST1234' which are the prioritised list.\n",
    "    - df_display: The main df that we can use.\n",
    "    - sheet_name_contents (str): Name of sheet to put contents in.\n",
    "    \"\"\"\n",
    "\n",
    "    index = ['standard_code']\n",
    "    index_standard = [cols_dictionary[c] for c in standard_cols if c in index]\n",
    "\n",
    "    delivery_comments = 'Delivery Comments'\n",
    "    \n",
    "    cols_for_contents = [\n",
    "        cols_dictionary[c] \n",
    "        for c in standard_cols \n",
    "        if c not in index\n",
    "        if c not in ['standard_overview', 'standard_page_url', 'level'] # Longer name cols\n",
    "    ] \n",
    "    cols_for_contents += [delivery_comments]\n",
    "\n",
    "    # Add empty column for coments\n",
    "    data = df_display.assign(**{delivery_comments: ''})\n",
    "    \n",
    "    df_standards = (\n",
    "        data\n",
    "        .rename(columns=cols_dictionary)\n",
    "        .set_index(index_standard) \n",
    "        [cols_for_contents]\n",
    "        .drop_duplicates()\n",
    "        .loc[st_codes]\n",
    "    )  \n",
    "    \n",
    "                 \n",
    "    write_df_to_excel(df_standards, writer, sheet_name=sheet_name_contents, startrow=2, index=True)\n",
    "\n",
    "    workbook = writer.book\n",
    "    wrap_format = workbook.add_format({'text_wrap': True, 'align': 'left'})\n",
    "\n",
    "    worksheet = writer.sheets[sheet_name_contents]\n",
    "    \n",
    "    max_n_columns = df_standards.shape[1]\n",
    "    \n",
    "    add_table_title_row(workbook, worksheet, 0, max_n_columns, 'List of standards in this file:')\n",
    "\n",
    "\n",
    "    for i, col in enumerate(index_standard + cols_for_contents):\n",
    "                        \n",
    "        if (col in long_text_cols) or (col == cols_dictionary['option_titles']):\n",
    "            width = 55\n",
    "        elif (col in title_cols):\n",
    "            width = 25\n",
    "        else:\n",
    "            width = 12\n",
    "                \n",
    "        if i == 0:\n",
    "            cell_format = None\n",
    "        else:\n",
    "            cell_format = wrap_format\n",
    "                \n",
    "        worksheet.set_column(i, i, width=width, cell_format=cell_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_table_title_row(workbook, worksheet, i, max_j, text_0, text_1=''):\n",
    "    \n",
    "    bold_grey_format = workbook.add_format({'bold': True, 'bg_color': '#D9D9D6', 'top': 1})\n",
    "    \n",
    "    for j in range(max_j + 1):\n",
    "        \n",
    "        if j == 0:\n",
    "            text = text_0\n",
    "        elif j == 1:\n",
    "            text = text_1\n",
    "        else:\n",
    "            text = ''\n",
    "            \n",
    "        worksheet.write(i, j, text, bold_grey_format)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_links(worksheet, dict_links, st_code, ifate_url, start_row):    \n",
    "    \n",
    "    for i, (link_name, link_url) in enumerate(dict_links.items()):\n",
    "        i_ = start_row + i\n",
    "        worksheet.write(i_, 0, link_name)\n",
    "        \n",
    "        link_url = link_url.format(st_code=st_code, ifate_url=ifate_url)\n",
    "        worksheet.write(i_, 2, link_url)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def output_to_excel(df_display, dict_links, st_codes, path):\n",
    "\n",
    "    index = ['standard_code', 'soc_2020_ext_code']\n",
    "    index_soc = [cols_dictionary[c] for c in soc_cols if c in index]\n",
    "    index_standard = [cols_dictionary[c] for c in standard_cols if c in index]\n",
    "    n_auto_suggestions = 20\n",
    "    \n",
    "    cols_to_show_soc = [cols_dictionary[c] for c in soc_cols if c not in index]\n",
    "    cols_to_show_standard = [cols_dictionary[c] for c in standard_cols if c not in index]\n",
    "    \n",
    "    with pd.ExcelWriter(path) as writer:\n",
    "        \n",
    "        create_intro(writer, list_text=intro_text, dict_col_descriptions=cols_meaning_dictionary, sheet_name_intro='Introduction')\n",
    "        \n",
    "        create_contents(writer, st_codes, df_display, sheet_name_contents='Contents')\n",
    "        \n",
    "        for i, st_code in enumerate(st_codes):\n",
    "        \n",
    "            print(f'- {st_code}')\n",
    "    \n",
    "            data = (\n",
    "                df_display\n",
    "                .assign(standard_title_=lambda df: df['standard_title'])\n",
    "                .loc[lambda df: df['standard_code'] == st_code]\n",
    "                .rename(columns=cols_dictionary)\n",
    "                .assign(prob_col=lambda df: df[cols_dictionary[prob_col]])\n",
    "            )\n",
    "            \n",
    "            this_cols_to_show_standard = list(cols_to_show_standard)\n",
    "            if not data['is_core_and_options'].max():\n",
    "                this_cols_to_show_standard.remove(cols_dictionary['option_titles'])\n",
    "            \n",
    "            for c in data.columns:\n",
    "                if (c.startswith('Similarity')) or (c == cols_dictionary[prob_col]):\n",
    "                    data[c] = np.where(\n",
    "                        data[c].isna(),\n",
    "                        'N/A',\n",
    "                        (data[c] * 100).round(1).astype(str) + '%',\n",
    "                    )\n",
    "            \n",
    "            data = data.fillna('N/A')\n",
    "            \n",
    "            data_standard = (\n",
    "                data\n",
    "                .head(1)\n",
    "                .set_index(index_standard)\n",
    "                [this_cols_to_show_standard]\n",
    "            )\n",
    "            \n",
    "    \n",
    "            data_suggestions = (\n",
    "                data\n",
    "                .sort_values('prob_col', ascending=False)\n",
    "                .set_index(index_soc)\n",
    "                [cols_to_show_soc]\n",
    "                .head(n_auto_suggestions)\n",
    "            )\n",
    "    \n",
    "            data_gatsby_suggestions = (\n",
    "                data\n",
    "                .loc[lambda df: df[cols_dictionary['match_rank_label']].astype(str) != '']\n",
    "                .sort_values('match_rank', ascending=True)\n",
    "                .set_index(index_soc)\n",
    "                [cols_to_show_soc]\n",
    "            )\n",
    "            \n",
    "            n_data_standard = data_standard.shape[0]\n",
    "            n_gatsby_suggestions = data_gatsby_suggestions.shape[0]\n",
    "            n_links = len(dict_links)\n",
    "    \n",
    "    \n",
    "            start_row_standard = 2\n",
    "            write_df_to_excel(data_standard, writer, sheet_name=st_code, startrow=start_row_standard)\n",
    "            \n",
    "            start_row_links = start_row_standard + n_data_standard + 5\n",
    "            \n",
    "            start_row_gatbsy = start_row_links + n_links + 4\n",
    "            write_df_to_excel(data_gatsby_suggestions, writer, sheet_name=st_code, startrow=start_row_gatbsy)\n",
    "\n",
    "            start_row_auto = start_row_gatbsy + n_gatsby_suggestions + 5\n",
    "            write_df_to_excel(data_suggestions, writer, sheet_name=st_code, startrow=start_row_auto)\n",
    "            \n",
    "            workbook  = writer.book\n",
    "            wrap_format = workbook.add_format({'text_wrap': True, 'align': 'left'})\n",
    "            title_format = workbook.add_format({'bold': True, 'border': True, 'valign': 'Top', 'text_wrap': True})\n",
    "            \n",
    "            worksheet = writer.sheets[st_code]\n",
    "            max_n_columns = max(data_standard.shape[1], data_suggestions.shape[1], data_gatsby_suggestions.shape[1])\n",
    "            add_table_title_row(workbook, worksheet, 0, max_n_columns, 'Table 1:', 'Standard Info:')\n",
    "            add_table_title_row(workbook, worksheet, start_row_links-2, max_n_columns, 'Table 2:', 'Useful Links')\n",
    "            add_table_title_row(workbook, worksheet, start_row_gatbsy-2, max_n_columns, 'Table 3:', 'Current SOC Assignments')\n",
    "            add_table_title_row(workbook, worksheet, start_row_auto-2, max_n_columns, 'Table 4:', f'Top {n_auto_suggestions} AI Suggested Assignments')\n",
    "            \n",
    "            \n",
    "            ifate_url = data[cols_dictionary['standard_page_url']].max()\n",
    "            add_links(worksheet, dict_links, st_code=st_code, ifate_url=ifate_url, start_row=start_row_links)\n",
    "\n",
    "            for i, col_soc in enumerate(index_soc + cols_to_show_soc):\n",
    "                \n",
    "                \n",
    "                if i <= len(this_cols_to_show_standard):\n",
    "                    col_standard = (index_standard + this_cols_to_show_standard)[i]\n",
    "                else:\n",
    "                    col_standard = None\n",
    "                    \n",
    "                if (col_standard in long_text_cols) or (col_soc in long_text_cols):\n",
    "                    width = 60\n",
    "                elif (col_standard in medium_text_cols) or (col_soc in medium_text_cols):\n",
    "                    width = 20\n",
    "                elif (col_standard in title_cols) or (col_soc in title_cols):\n",
    "                    width = 15\n",
    "                else:\n",
    "                    width = 10\n",
    "                \n",
    "                if i == 0:\n",
    "                    cell_format = None\n",
    "                else:\n",
    "                    cell_format = wrap_format\n",
    "                \n",
    "                if col_standard == cols_dictionary['option_titles']:\n",
    "                    option_titles = data_standard[col_standard].max().replace('; ', '\\n')\n",
    "                    n_options = option_titles.count('\\n') + 1\n",
    "                    \n",
    "                    option_column_name = col_standard\n",
    "                    if n_options > 2:\n",
    "                        option_column_name = f'{option_column_name} (Adjust cell height to see all)'\n",
    "                        \n",
    "                    worksheet.merge_range(start_row_standard, i, start_row_standard, i+2, option_column_name, title_format)\n",
    "                    worksheet.merge_range(start_row_standard+1, i, start_row_standard+1, i+2, option_titles, wrap_format)\n",
    "                    \n",
    "                    #if data['is_core_and_options'].max():\n",
    "                    #    worksheet.set_row(start_row_standard+1, max(2, n_options) * 15.0001)\n",
    "                    \n",
    "                if col_soc == cols_dictionary['standard_typical_job_title']:\n",
    "                    if n_gatsby_suggestions > 0:\n",
    "                        worksheet.merge_range(start_row_gatbsy, i, start_row_gatbsy, i+1, cols_dictionary['standard_typical_job_title'], title_format)\n",
    "                    worksheet.merge_range(start_row_auto, i, start_row_auto, i+1, cols_dictionary['standard_typical_job_title'], title_format)\n",
    "\n",
    "                worksheet.set_column(i, i, width=width, cell_format=cell_format)\n",
    "                    \n",
    "                if col_soc == cols_dictionary['prob_col_label']:\n",
    "                    for k, colour in dict_rayg_colours.items():\n",
    "                        colour_format = workbook.add_format({'bg_color': colour, 'border': True})\n",
    "                        worksheet.conditional_format(\n",
    "                            start_row_gatbsy, i, (start_row_auto + 21), i, \n",
    "                            {'type':     'cell',\n",
    "                             'criteria': '=',\n",
    "                             'value':  f'\"{dict_rayg_label[k]}\"',\n",
    "                             'format': colour_format,\n",
    "                            }\n",
    "                        )                \n",
    "                                \n",
    "    print(f'Written to {path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_assignment_table(df_display, st_codes, path, sheet_name='SOC Assignments'):\n",
    "    \n",
    "    index = ['standard_code']\n",
    "    \n",
    "    data_spine = (\n",
    "        df_display\n",
    "        .set_index('standard_code')\n",
    "        .loc[st_codes]\n",
    "        [['standard_title', 'route']]\n",
    "        .assign(**{'Approved by RH': False})\n",
    "        .drop_duplicates()\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    data_gatsby_suggestions = (\n",
    "        df_display\n",
    "        .loc[lambda df: df['standard_code'].isin(st_codes)]    \n",
    "        .loc[lambda df: ~df['match_rank'].isna()]\n",
    "        .sort_values('match_rank', ascending=True)\n",
    "    )\n",
    "\n",
    "    data_gatsby_suggestions_pivot = pd.pivot_table(\n",
    "        data_gatsby_suggestions,\n",
    "        index = index,\n",
    "        columns='match_rank_label',\n",
    "        values='soc_2020_ext_code',\n",
    "        aggfunc=max,\n",
    "        fill_value='',\n",
    "    )\n",
    "    \n",
    "    # re-order cols\n",
    "    max_rank = int(data_gatsby_suggestions['match_rank'].max())\n",
    "    cols = ['Primary'] + [f'Alternative #{i}' for i in range(1, max_rank)]\n",
    "    data_gatsby_suggestions_pivot = data_gatsby_suggestions_pivot[cols].reset_index()\n",
    "    \n",
    "    index = [cols_dictionary[c] for c in index]\n",
    "    data_gatsby_suggestions_pivot = (\n",
    "        data_spine\n",
    "        .merge(\n",
    "            data_gatsby_suggestions_pivot,\n",
    "            how='left',\n",
    "        )\n",
    "        .rename(columns=cols_dictionary)\n",
    "        .set_index(index)\n",
    "    )\n",
    "    \n",
    "    with pd.ExcelWriter(path) as writer:                \n",
    "        write_df_to_excel(data_gatsby_suggestions_pivot, writer, sheet_name=sheet_name, startrow=0)\n",
    "        \n",
    "        workbook  = writer.book\n",
    "        \n",
    "        wrap_format = workbook.add_format({'text_wrap': True, 'align': 'left'})\n",
    "        \n",
    "        worksheet = writer.sheets[sheet_name]\n",
    "        worksheet.set_column(0, 20, width=10, cell_format=wrap_format)\n",
    "        worksheet.set_column(1, 2, width=17, cell_format=wrap_format)\n",
    "            \n",
    "    print(f'Written to {path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_links = {\n",
    "    'IfATE Standard Page:': '{ifate_url}',\n",
    "    'IDS for Data Entry:': 'https://ids/admin/summaries/summarysubmission/?q={st_code}',\n",
    "    'Process Guidance:': 'https://educationgovuk.sharepoint.com/:w:/s/DDST/ESyFp4lTgydBlm3Af1M5Fu0BdeM99OhJKwffJ61QUZoRaQ?e=klKTmN',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_table(df_display, st_codes, label):\n",
    "    \n",
    "    timestamp = datetime.datetime.today().strftime('%Y%m%d_%H%M')\n",
    "    \n",
    "    results_file_name = f'export_results_{label}_{run_version}__{timestamp}.xlsx'\n",
    "    \n",
    "    path_gatbsy_export_excel = Path('nsfg_data', results_file_name)\n",
    "    output_to_excel(df_display, dict_links, st_codes, path_gatbsy_export_excel)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "st_codes = ['ST0752', 'ST0003', 'ST1358', 'ST0585', 'ST0456']\n",
    "create_results_table(df_display, st_codes, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 20 Prio'd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_prio_st_codes = list(\n",
    "    df_prio\n",
    "    .sort_values('prio_ranked')\n",
    "    .reset_index()\n",
    "    .head(20)\n",
    "    ['standard_code']\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "create_results_table(df_display, list_prio_st_codes, 'prio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_low_prio_st_codes = list(\n",
    "    df_prio\n",
    "    .sort_values('prio_ranked', ascending=False)\n",
    "    .reset_index()\n",
    "    .head(20)\n",
    "    ['standard_code']\n",
    ")  \n",
    "create_results_table(df_display, list_low_prio_st_codes, 'low_prio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prio By Route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "routes = df_prio['route'].unique()\n",
    "\n",
    "for this_route in routes:\n",
    "    print(f'**** Doing {this_route} ****')\n",
    "    list_prio_route_st_codes = (\n",
    "        df_prio\n",
    "        .reset_index()\n",
    "        .loc[lambda df: df['route'] == this_route]\n",
    "        .loc[lambda df: df['prio_ranked'] <= 250]\n",
    "        .sort_values('prio_ranked', ascending=True)\n",
    "        .reset_index()\n",
    "        ['standard_code']\n",
    "    )  \n",
    "    create_results_table(df_display, list_prio_route_st_codes, f'prio_{this_route}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_route = 'Digital'\n",
    "\n",
    "list_prio_route_st_codes = (\n",
    "    df_prio\n",
    "    .reset_index()\n",
    "    .loc[lambda df: df['route'] == this_route]\n",
    "    .sort_values('prio_ranked', ascending=False)\n",
    "    .head(10)\n",
    "    .reset_index()\n",
    "    ['standard_code']\n",
    ")  \n",
    "\n",
    "create_results_table(df_display, list_prio_route_st_codes, f'low_prio_{this_route}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Laurie's Analytical Kernel",
   "language": "python",
   "name": "venv_ana"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
